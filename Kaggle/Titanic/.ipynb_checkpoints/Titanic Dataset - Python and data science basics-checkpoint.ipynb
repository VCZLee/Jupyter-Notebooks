{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting starting with data analysis in python\n",
    "Previously, I've only done data analysis in R. Here's my first real try of doing something besides linear regression/GLMs in Python.\n",
    "\n",
    "The titanic dataset is a dataset of the passengers onboard the ill-fated titanic when it sunk over a century ago. Let's see if we can predict whether or not a passenger would've survived based on the other characteristics we knew about them.\n",
    "\n",
    "Let's use pandas, import the classic titanic dataset, and print the columns names, and the top 7 rows of the dataset as a sanity check/ quick look of the data we're importing. \n",
    "\n",
    "Note that this is the training dataset; we'll be setting aside the testing dataset to see how well our models generalize to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'C:/Users/vlee/PycharmProjects/Jupyter-Notebooks/Kaggle/Titanic/Data/train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7a2419865659>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/vlee/PycharmProjects/Jupyter-Notebooks/Kaggle/Titanic/Data/train.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# Originally, I had issues importing data as the first column was not being recognized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# When you import csv files using pandas, by default the first column of the file is an index column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mfrom_csv\u001b[1;34m(cls, path, header, sep, index_col, parse_dates, encoding, tupleize_cols, infer_datetime_format)\u001b[0m\n\u001b[0;32m   1249\u001b[0m                           \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m                           \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtupleize_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtupleize_cols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1251\u001b[1;33m                           infer_datetime_format=infer_datetime_format)\n\u001b[0m\u001b[0;32m   1252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'block'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'C:/Users/vlee/PycharmProjects/Jupyter-Notebooks/Kaggle/Titanic/Data/train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    train = pd.DataFrame.from_csv('C:/Users/vlee/PycharmProjects/Jupyter-Notebooks/Kaggle/Titanic/Data/train.csv', index_col = None)\n",
    "    \n",
    "# Originally, I had issues importing data as the first column was not being recognized\n",
    "# When you import csv files using pandas, by default the first column of the file is an index column\n",
    "# index_col=None tells pandas that the first column given is a column with actual data\n",
    "\n",
    "print(\"Here is a list of the column names: \" + str(train.columns.values))\n",
    "print(\"Here are the dimensions of our training dataset in (row, column) form: \" + str(train.shape))\n",
    "train.head(n=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a training dataset with 891 rows, and 12 columns: 'PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
    " 'Ticket', 'Fare', 'Cabin', 'Embarked'\n",
    "\n",
    "It looks like some of the columns may be unsuitable for prediction. Let's see what the columns are actually representing. Here's an explanation of the variables taken from Kaggle.\n",
    "\n",
    "\n",
    "## Data Dictionary\n",
    "survival\t- Survival\t0 = No, 1 = Yes\n",
    "\n",
    "pclass\t- Ticket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "\n",
    "sex\t- Sex\t\n",
    "\n",
    "Age\t- Age in years\t\n",
    "\n",
    "sibsp -\t# of siblings / spouses aboard the Titanic\t\n",
    "\n",
    "parch -\t# of parents / children aboard the Titanic\t\n",
    "\n",
    "ticket -\tTicket number\t\n",
    "\n",
    "fare -\tPassenger fare\t\n",
    "\n",
    "cabin -\tCabin number\t\n",
    "\n",
    "embarked -\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "pclass: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    "age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "sibsp: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fiancÃ©s were ignored)\n",
    "\n",
    "parch: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "\n",
    "\n",
    "## Sanity check of variables\n",
    "\n",
    "Some variables that should stand out are the \"Name\", \"Ticket\" and \"PassengerId\" columns. By intuition, the name should not be a significant determinant in whether or not someone died in a ship sinking. The same goes for the passenger id, which is just an index variable assigned to the dataset well after the event. \n",
    "\n",
    "In a similar fashion, the ticket number shouldn't really matter either. From pulling the first 7 ticket numbers from the data set, we see that ticket numbers have no clear meaning, as some of the ticket numbers have characters included, and the numbers range from 17463 to 373450, which means that the ticket number does not match the number of passengers either, or boarding order, as the titanic certainly did not have room for 300,000 people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Janitor Work\n",
    "\n",
    "Since we've identified the Name, Ticket and PassengerId columns are not being particularly useful in predicting whether or not a given titanic passenger would've survived, let's drop those first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['PassengerId','Name','Ticket'], axis = 1, inplace = True)\n",
    "train.head(n=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks better. Looks like we might have some missing data (The fifth entry has a missing age value, and the Cabin column has many missing values - 'NaN'). Let's see if we have any missing data values elsewhere in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have some missing data. The Age, Cabin, and Embarked columns have some missing values. We will need to deal with this. \n",
    "\n",
    "A lot of records are missing cabin numbers. Cabin numbers seem to be formatted with a combination of a letter at the beginning, followed by a number. While the letter at the beginning may indicate what section of the ship the passenger was in, \"pclass\" would be an excellent proxy, as what class your ticket was determined what section of the ship you were placed in, and it has no missing values. \n",
    "\n",
    "Let's remove the \"Cabin\" column.\n",
    "\n",
    "The age and the embarked columns are a little more problematic however, and cannot be dealt with by simply removing their columns. \n",
    "\n",
    "We can remove the data entries/ passengers who have missing embarkation data, as there are only two passengers who are missing embarkation data. However, with regards to age, we could drop the age column, but that leaves the issue of us dropping a lot of data - age certainly was a factor in one's survival on the titanic - \"women and children first\". \n",
    "\n",
    "We could just exlude the passenger entries with missing age values, but we don't know how many passengers in the testing data set lack ages. What will happen if our model, if trained with age as an input, needs to guess whether or not a passenger whose age is unknown survived? \n",
    "\n",
    "For now, let's just exclude the passengers with missing age values from our training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.drop(['Cabin'], axis = 1, inplace = True)\n",
    "train.dropna(subset = [\"Age\",\"Embarked\"], inplace = True)\n",
    "print(train.isnull().sum())\n",
    "print(\"Here are the dimensions of our training dataset in (row, column) form: \" + str(train.shape))\n",
    "train.head(n=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. Worth nothing however, is the fact that our training now only has 712 observations, compared to the original 891, a 20% reduction.\n",
    "\n",
    "Now's lets get some summary statistics of the columns to get an idea of how the data is distributed, and to see if there are any persisting issues with data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since survived is really just a binary variable, with 1 meaning the passenger survived the sinking and 0 meaning the passenger did not, the mean of the survived variable is actually the proportion of passengers who survived. \n",
    "\n",
    "Pclass's statistics is probably the least interpretable. While the values for Pclass are numeric (1, 2, 3), Pclass should really be a categorical variable. Categorical variable tell us the quality of something, numeric values tell us the quantity. \n",
    "\n",
    "The statistics for the Sex column are not displayed as it is coded as a categorical variable already, only being able to take on the values of \"male\" and \"female\" as opposed to numbers like Pclass. The same goes for the embarked column. \n",
    "\n",
    "Age, SibSp, Parch, and Fare all look normal. \n",
    "SibSp and Parch only take on integer values in the their histograms, which at least shows that there aren't obvious data quality issues.\n",
    "\n",
    "Average age is 29.64. Worth noting is that there are two \"humps\" in the distribution (see age histogram below), with one being near the mean of 29.64, and another smaller one near age 0, which suggests that there was a significant population of infants and children aboard. \n",
    "\n",
    "The average number of siblings/spouses a given passenger had was 0.51\n",
    "The average number of parents/children a given passenger had was 0.43\n",
    "The average fare paid by passengers is 34.56\n",
    "\n",
    "Let's plot histograms of the variables, and see if there are any issues in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in train.columns.values:\n",
    "    try:\n",
    "        histo = train.hist(column = column_name, bins = 25)\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass \n",
    "# use try/except because pandas will give you an error if you try to plot a histogram of a column with non-number values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms are in line with expectations based off the descriptive statistics, and are in line with intuition and common sense (i.e. no negative numbers for any of the variables, and integer only values for SibSp and Parch) \n",
    "\n",
    "Since logistic regressions can only accept numerical input, we need turn several variables into dummy variables.\n",
    "Instead of having C, Q, and S as the values for the Embarked variable, we'll just have dummy variables. For example: let Embarked C be equal to 1 if the value for the Embarked column was C, and 0 otherwise, and the same for Embarked Q and S. \n",
    "\n",
    "As mentioned before, we need to process the Pclass column and turn it into a categorical variable. The same goes for the Sex and Embarked columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.get_dummies(data = train, columns = ['Pclass', 'Sex', 'Embarked'])\n",
    "train.head(n = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks good. We'll need to drop one dummy variable for each of our three original categorical variables. This is so we can establish a \"baseline\" category. For example, if we drop the sex_male column, the model will assume the passenger is male unless otherwise specified by the sex_female column with a 1. We'll pick the most common category for each categorical variable to be our baseline (see histograms above), and in this case, the baseline assumption is 3rd class, Male, and embarked at Southhampton, until otherwise specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()\n",
    "train.drop(['Pclass_3', 'Sex_male', 'Embarked_S'], axis = 1, inplace = True)\n",
    "train.head(n = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting\n",
    "## Generalized Linear Model (Logistic Regression)\n",
    "\n",
    "Let's finally build a model to predict passenger survivorship based off our now cleaned data. We'll be fitting a logistic regression (a kind of Generalized Linear Model or GLM) which will output a number between 0 and 1, with 0 being a prediction of dying, and 1 being a prediction of surviving. We can interpret numbers between 0 and 1 as how likely a passenger with the given attributes would survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "train_cols =  train.columns[1:]\n",
    "logit = sm.Logit(train['Survived'], train[train_cols])\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table is a table of the results from training our logistic model. Some figures to note are the Pseudo R-Squared figure which shows how good our model predicts survival, and the various coefficients of our variables and their respective P-values, which shows the relative \"importance\" of our variables in determining survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display\n",
    "train_age = train.copy() #save the dataframe before we add our predictions to it\n",
    "train['Probability'] = result.predict(train[train_cols])\n",
    "train['Predicted'] = np.where(train['Probability'] >= 0.5, 1 ,0)\n",
    "train.head(n = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the model we've trained using the training set, we can output the model's confidence of a given passenger surviving, as seen in the probability column. To better evaluate model performance, we discretize the confidence output: survival probabilities above 0.5 will be considered to have survived and less than 0.5 will be considered to have died. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# confusion_matrix(train['Survived'], train['Predicted'])\n",
    "\n",
    "train_cmatrix = pd.crosstab(np.where(train['Survived'] == 1, 'Survived', 'Died'), \n",
    "                            np.where(train['Predicted'] == 1, 'Survived', 'Died'),\n",
    "                            rownames=['Actual'],\n",
    "                            colnames=['Predicted'],\n",
    "                            margins=True)\n",
    "display(train_cmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is a confusion matrix, which shows what happened in reality vs. what the model predicted. For example, out of the 712 passengers in the training dataset, there were 63 instances where the model predicted that they would survive, when in reality they had died. \n",
    "\n",
    "We can use the F1 score to quantify how well our GLM is performing. It is the harmonic average of precision and recall, with precision being the proportion of predicted survivors that had actually survived, and recall being the proportion of all actual survivors being predicted to survive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tp = train_cmatrix['Survived']['Survived']\n",
    "train_fp = train_cmatrix['Survived']['Died']\n",
    "train_fn = train_cmatrix['Died']['Survived']\n",
    "train_precision = train_tp/(train_tp + train_fp)\n",
    "train_recall = train_tp/(train_tp + train_fn)\n",
    "train_f1 = 2/(train_precision**-1 + train_recall**-1)\n",
    "print(\"The F1 Score of the model on the training dataset is \" + str(train_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 scores range from 0 to 1, where 1 is perfect performance (all actual survivors are predicted to survive by the model, with no false positives/ negatives). Our model is, at the very least, acceptable, and is doing better than random guessing. \n",
    "\n",
    "# Initial Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival = pd.DataFrame.from_csv('C:/Users/vlee/PycharmProjects/Jupyter-Notebooks/Kaggle/Titanic/Data/gender_submission.csv', index_col = None)\n",
    "test = pd.DataFrame.from_csv('C:/Users/vlee/PycharmProjects/Jupyter-Notebooks/Kaggle/Titanic/Data/test.csv', index_col = None)\n",
    "test.drop(['Name','Ticket','Cabin'], axis = 1, inplace = True)\n",
    "test = pd.get_dummies(data = test, columns = ['Pclass', 'Sex', 'Embarked'])\n",
    "test = survival.merge(test, on = 'PassengerId')\n",
    "print(\"Here are the dimensions of our testing dataset, before removing rows with missing data, in (row, column) form: \" + str(test.shape))\n",
    "\n",
    "test_missing = test[pd.isnull(test['Age'])].copy()\n",
    "test_missing.drop(['PassengerId', 'Pclass_3', 'Sex_male', 'Embarked_S'], axis = 1, inplace = True)\n",
    "\n",
    "test.dropna(subset = ['Age'], inplace = True)\n",
    "test.drop(['PassengerId', 'Pclass_3', 'Sex_male', 'Embarked_S'], axis = 1, inplace = True)\n",
    "test_cols = test.columns[1:]\n",
    "test['Probability'] =  result.predict(test[test_cols])\n",
    "test['Predicted'] = np.where(test['Probability'] >= 0.5, 1, 0)\n",
    "print(\"Here are the dimensions of our testing dataset, after removing rows with missing data, in (row, column) form: \" + str(test.shape))\n",
    "test.head(n = 7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that around 20% of our testing data has missing age values, and needed to be removed. This is similar to the proportion of passengers we removed from the training set. We will deal with predictions for passengers with missing data values later. For now, let's see how our model performs on passengers with complete infomration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cmatrix = pd.crosstab(np.where(test['Survived'] == 1, 'Survived', 'Died'), \n",
    "                            np.where(test['Predicted'] == 1, 'Survived', 'Died'),\n",
    "                            rownames=['Actual'],\n",
    "                            colnames=['Predicted'],\n",
    "                            margins=True)\n",
    "display(test_cmatrix)\n",
    "test_tp = test_cmatrix['Survived']['Survived']\n",
    "test_fp = test_cmatrix['Survived']['Died']\n",
    "test_fn = test_cmatrix['Died']['Survived']\n",
    "test_precision = test_tp/(test_tp + test_fp)\n",
    "test_recall = test_tp/(test_tp + test_fn)\n",
    "test_f1 = 2/(test_precision**-1 + test_recall**-1)\n",
    "print(\"The F1 Score of the model on the test dataset is \" + str(test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Strangely enough, the model seems to have a better time predicting survival on the testing set, a set it's never \"seen\" before, as opposed to the training set on which it was trained on. This is a sign that the model generalizes well, as opposed to being overfit. This might be a sign that the model isn't learning as much as it could be from the training set. \n",
    "\n",
    "# Data Imputation\n",
    "\n",
    "But what about all the passengers whose ages weren't recorded? We could simply just not predict survival chances for them, but that's honestly a cheap cop-out, and we're ignoring around 20% of all passengers.\n",
    "\n",
    "We could train another GLM that doesn't rely on age information, but based on historical(\"Women and children first!\") and statistical(The age variable in our original GLM is highly significant in determining survival chances) reasons, that would not be a good idea. We would weaken the predictive power of our model.\n",
    "\n",
    "Since our GLM only takes passengers whose information records are complete we need to find away to deal with people without ages recorded.\n",
    "\n",
    "## Mean Value Imputation\n",
    "\n",
    "A fast, basic approach to data imputation is to simply take the mean value of the column with missing values, and use the mean to fill in observations with missing variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_missing.head(n = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_missing_alt = test_missing.copy()\n",
    "test_missing.loc[:, 'Age'] = train['Age'].mean()\n",
    "test_missing.head(n = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_missing_cols = test_missing.columns[1:]\n",
    "test_missing['Probability'] =  result.predict(test_missing[test_cols])\n",
    "test_missing['Predicted'] = np.where(test_missing['Probability'] >= 0.5, 1, 0)\n",
    "test_missing.head(n = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_missing_cmatrix = pd.crosstab(np.where(test_missing['Survived'] == 1, 'Survived', 'Died'), \n",
    "                            np.where(test_missing['Predicted'] == 1, 'Survived', 'Died'),\n",
    "                            rownames=['Actual'],\n",
    "                            colnames=['Predicted'],\n",
    "                            margins=True)\n",
    "display(test_missing_cmatrix)\n",
    "test_missing_tp = test_missing_cmatrix['Survived']['Survived']\n",
    "test_missing_fp = test_missing_cmatrix['Survived']['Died']\n",
    "test_missing_fn = test_missing_cmatrix['Died']['Survived']\n",
    "test_missing_precision = test_missing_tp/(test_missing_tp + test_missing_fp)\n",
    "test_missing_recall = test_missing_tp/(test_missing_tp + test_missing_fn)\n",
    "test_missing_f1 = 2/(test_missing_precision**-1 + test_missing_recall**-1)\n",
    "print(\"The F1 Score of the model on the test dataset is \" + str(test_missing_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After replacing the missing passenger ages with the average passenger age from the training set, we get a lower F1 score compared to the F1 score of the testing dataset without missing age values. \n",
    "\n",
    "While now we can finally predict the survival of passengers whose age is unknown, the fact that we imputed age with the average age seems to have had a negative impact in terms of model performance. This is because age is one of the variables with the highest impact on survival (see the z-values from the logistic model regression results), and we lose a lot of predictive power if we just use the average age. \n",
    "\n",
    "## Regression Imputation\n",
    "\n",
    "Since we have age data on roughly 80% of the passengers, we can impute the missing ages using another model.\n",
    "\n",
    "We'll use another logistic regression to predict passenger's ages based on the remaining variables: Sibling/spouse count, Parent/children count, gender, embarkation point, ticket class, and fare. \n",
    "\n",
    "While logistic regressions are typically used to predict binary variables (such as dead/alive in our previous model), it has a useful property that we can exploit: it only returns values between 0 and 1. This lets us restrict the range of age predictions our model makes, so that we won't get non-sensical values such as negative ages or extremely high ages. \n",
    "\n",
    "We can transform the age values such that they're within the [0, 1] range that the logistic model can handle.\n",
    "\n",
    "Data normalization involved scaling a variable so that all possible values are between 0 and 1, where 0 and 1 are the minimum and maximum values of the variable, repsectively.\n",
    "\n",
    "$$x_{normalized} = \\frac {x_{original} - x_{minimum}}{x_{maximum} - x_{minimum}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "train_age = train.drop(['Survived', 'Probability', 'Predicted'], axis = 1, inplace = False)\n",
    "# age_min = 0\n",
    "# age_max = 80\n",
    "import numpy as np\n",
    "train_cols = train_age.columns[1:]\n",
    "scaler_age = preprocessing.MinMaxScaler(feature_range = (0, 1)).fit(train_age[['Age']])\n",
    "train_age.loc[:, 'Age'] = scaler_age.transform(train_age[['Age']])\n",
    "age_model = sm.Logit(train_age['Age'], train_age[train_cols])\n",
    "age_model_result = age_model.fit()\n",
    "age_model_result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_age['Predicted'] = scaler_age.inverse_transform(age_model_result.predict(train_age[train_cols]).values.reshape(-1, 1))\n",
    "train_age.loc[:, 'Age'] = scaler_age.inverse_transform(train_age[['Age']])\n",
    "train_age.head(n = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting our logistic regression, we'll need to see how much of a performance boost is it compared to just using the mean age. We'll need to quantify performance using a different method than using a confusion matrix/ F1 score, since those only make sense for models that predict class/category (i.e. survived/ died). Since we're predicting age, a continuous variable, we'll use the sum of squared error measure. For each passenger, we'll take the squared difference between the predicted and actual age (so it'll always be positive), and then sum up the errors for all passengers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_error_regression = ((train_age['Age'] - train_age['Predicted']) ** 2).sum()\n",
    "squared_error_mean = ((train_age['Age'] - train_age['Age'].mean()) ** 2).sum()\n",
    "print(\"The Sum of Squared Errors for regression imputation is \" + str(squared_error_regression))\n",
    "print(\"The Sum of Squared Errors for mean-value imputation is \"+ str(squared_error_mean))\n",
    "performance_percentage = squared_error_regression/squared_error_mean\n",
    "if performance_percentage < 1:\n",
    "    print(\"The regression imputation method has a squared error sum \" + \n",
    "          str(100 * (1 - performance_percentage)) + \n",
    "          \"% greater than the mean imputation method\")\n",
    "else:     print(\"The regression imputation method has a squared error sum \" + \n",
    "          str(100 * (performance_percentage - 1)) + \n",
    "          \"% less than the mean imputation method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our age GLM (logistic regression) does not predict age any better than than just using the mean age when it comes to accuracy.\n",
    "\n",
    "Nevertheless, since our survival GLM relies on age heavily, let's see how our survival GLM performs based on the ages the age GLM predicted for our ageless passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_missing_alt['Age'] = scaler_age.inverse_transform(age_model_result.predict(test_missing_alt[train_cols]).values.reshape(-1, 1))\n",
    "test_missing_alt['Probability'] = result.predict(test_missing_alt[test_cols])\n",
    "test_missing_alt['Predicted'] = np.where(test_missing_alt['Probability'] >= 0.5, 1, 0)\n",
    "test_missing_alt.head(n = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_missing_alt_cmatrix = pd.crosstab(np.where(test_missing_alt['Survived'] == 1, 'Survived', 'Died'), \n",
    "                            np.where(test_missing_alt['Predicted'] == 1, 'Survived', 'Died'),\n",
    "                            rownames=['Actual'],\n",
    "                            colnames=['Predicted'],\n",
    "                            margins=True)\n",
    "display(test_missing_alt_cmatrix)\n",
    "test_missing_alt_tp = test_missing_alt_cmatrix['Survived']['Survived']\n",
    "test_missing_alt_fp = test_missing_alt_cmatrix['Survived']['Died']\n",
    "test_missing_alt_fn = test_missing_alt_cmatrix['Died']['Survived']\n",
    "test_missing_alt_precision = test_missing_alt_tp/(test_missing_alt_tp + test_missing_alt_fp)\n",
    "test_missing_alt_recall = test_missing_alt_tp/(test_missing_alt_tp + test_missing_alt_fn)\n",
    "test_missing_alt_f1 = 2/(test_missing_alt_precision**-1 + test_missing_alt_recall**-1)\n",
    "print(\"The F1 Score of the model on the test dataset is \" + str(test_missing_alt_f1))\n",
    "print(\"Using regression imputation results in a \" + str(((test_missing_alt_f1 - test_missing_f1)/(test_missing_f1)) * 100) + \"% increase in the F1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our age GLM to predict passenger ages only in a ~4.7% increase in squared errors as opposed to just using the average age, when we used the GLM-predicted ages to predict survival, we got a 36% improvement in the F1 score among the ageless passengers. Not an intuitive result, but perhaps using the sum of squared errors as a way to evalute model accuracy was not a good way to estimate model performance in this case. Regardless,there are certainly some very promising results. \n",
    "\n",
    "For the sake of practice and completeness, let's try using other algorithms to try to predict passenger survival.\n",
    "\n",
    "# Model Fitting\n",
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector machines attempt to find the plane of maximum seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize training and testing datasets for SVM fitting and prediction\n",
    "train_svm = train.drop(['Probability','Predicted'], axis = 1, inplace = False)\n",
    "test_svm = test.drop(['Probability','Predicted'], axis = 1, inplace = False)\n",
    "\n",
    "scaled_train_svm = train_svm.copy()\n",
    "scaler_svm = preprocessing.MinMaxScaler().fit(scaled_train_svm[['Age', 'SibSp', 'Parch', 'Fare']])\n",
    "scaled_train_svm[['Age', 'SibSp', 'Parch', 'Fare']] = scaler_svm.transform(scaled_train_svm[['Age', 'SibSp', 'Parch', 'Fare']])\n",
    "\n",
    "from sklearn import svm\n",
    "train_cols = scaled_train_svm.columns[1:]\n",
    "survivalsvm = svm.SVC(kernel = 'rbf', gamma = 0.001, C = 1000, decision_function_shape = 'ovr').fit(scaled_train_svm[train_cols], scaled_train_svm['Survived'])\n",
    "scaled_train_svm['Predicted'] = survivalsvm.predict(scaled_train_svm[train_cols])\n",
    "\n",
    "train_svm_cmatrix = pd.crosstab(np.where(scaled_train_svm['Survived'] == 1, 'Survived', 'Died'), \n",
    "                            np.where(scaled_train_svm['Predicted'] == 1, 'Survived', 'Died'),\n",
    "                            rownames=['Actual'],\n",
    "                            colnames=['Predicted'],\n",
    "                            margins=True)\n",
    "display(train_svm_cmatrix)\n",
    "\n",
    "train_svm_tp = train_svm_cmatrix['Survived']['Survived']\n",
    "train_svm_fp = train_svm_cmatrix['Survived']['Died']\n",
    "train_svm_fn = train_svm_cmatrix['Died']['Survived']\n",
    "train_svm_precision = train_svm_tp/(train_svm_tp + train_svm_fp)\n",
    "train_svm_recall = train_svm_tp/(train_svm_tp + train_svm_fn)\n",
    "train_svm_f1 = 2/(train_svm_precision**-1 + train_svm_recall**-1)\n",
    "print(\"The F1 Score of the SVM model on the training dataset is \" + str(train_svm_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test_svm = test_svm.copy()\n",
    "scaled_test_svm.dropna(inplace = True)\n",
    "scaled_test_svm[['Age', 'SibSp', 'Parch', 'Fare']] = scaler_svm.transform(scaled_test_svm[['Age', 'SibSp', 'Parch', 'Fare']])\n",
    "scaled_test_svm['Predicted'] = survivalsvm.predict(scaled_test_svm[train_cols])\n",
    "\n",
    "test_svm_cmatrix = pd.crosstab(np.where(scaled_test_svm['Survived'] == 1, 'Survived', 'Died'), \n",
    "                            np.where(scaled_test_svm['Predicted'] == 1, 'Survived', 'Died'),\n",
    "                            rownames=['Actual'],\n",
    "                            colnames=['Predicted'],\n",
    "                            margins=True)\n",
    "display(test_svm_cmatrix)\n",
    "\n",
    "test_svm_tp = test_svm_cmatrix['Survived']['Survived']\n",
    "test_svm_fp = test_svm_cmatrix['Survived']['Died']\n",
    "test_svm_fn = test_svm_cmatrix['Died']['Survived']\n",
    "test_svm_precision = test_svm_tp/(test_svm_tp + test_svm_fp)\n",
    "test_svm_recall = test_svm_tp/(test_svm_tp + test_svm_fn)\n",
    "test_svm_f1 = 2/(test_svm_precision**-1 + test_svm_recall**-1)\n",
    "print(\"The F1 Score of the SVM model on the testing dataset is \" + str(test_svm_f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
