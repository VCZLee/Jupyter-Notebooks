{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting starting with data analysis in python\n",
    "Previously, I've only done data analysis in R. Here's my first real try of doing something besides linear regression/GLMs in Python.\n",
    "\n",
    "The titanic dataset is a dataset of the passengers onboard the ill-fated titanic when it sunk over a century ago. Let's see if we can predict whether or not a passenger would've survived based on the other characteristics we knew about them.\n",
    "\n",
    "Let's use pandas, import the classic titanic dataset, and print the columns names, and the top 7 rows of the dataset as a sanity check/ quick look of the data we're importing. \n",
    "\n",
    "Note that this is the training dataset; we'll be setting aside the testing dataset to see how well our models generalize to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a list of the column names: ['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Cabin' 'Embarked']\n",
      "Here are the dimensions of our training dataset in (row, column) form: (891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    train = pd.DataFrame.from_csv('C:/Users/vlee/PycharmProjects/Jupyter-Notebooks/Kaggle/Titanic/Data/train.csv', index_col = None)\n",
    "except:\n",
    "    train = pd.DataFrame.from_csv('C:/Users/Jintoboy/PycharmProjects/Jupyter-Notebooks/Kaggle/Titanic/Data/train.csv', index_col = None)\n",
    "# Originally, I had issues importing data as the first column was not being recognized\n",
    "# When you import csv files using pandas, by default the first column of the file is an index column\n",
    "# index_col=None tells pandas that the first column given is a column with actual data\n",
    "\n",
    "print(\"Here is a list of the column names: \" + str(train.columns.values))\n",
    "print(\"Here are the dimensions of our training dataset in (row, column) form: \" + str(train.shape))\n",
    "train.head(n=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a training dataset with 891 rows, and 12 columns: 'PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
    " 'Ticket', 'Fare', 'Cabin', 'Embarked'\n",
    "\n",
    "It looks like some of the columns may be unsuitable for prediction. Let's see what the columns are actually representing. Here's an explanation of the variables taken from Kaggle.\n",
    "\n",
    "\n",
    "## Data Dictionary\n",
    "survival\t- Survival\t0 = No, 1 = Yes\n",
    "\n",
    "pclass\t- Ticket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "\n",
    "sex\t- Sex\t\n",
    "\n",
    "Age\t- Age in years\t\n",
    "\n",
    "sibsp -\t# of siblings / spouses aboard the Titanic\t\n",
    "\n",
    "parch -\t# of parents / children aboard the Titanic\t\n",
    "\n",
    "ticket -\tTicket number\t\n",
    "\n",
    "fare -\tPassenger fare\t\n",
    "\n",
    "cabin -\tCabin number\t\n",
    "\n",
    "embarked -\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "pclass: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    "age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "sibsp: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fianc√©s were ignored)\n",
    "\n",
    "parch: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "\n",
    "\n",
    "## Sanity check of variables\n",
    "\n",
    "Some variables that should stand out are the \"Name\", \"Ticket\" and \"PassengerId\" columns. By intuition, the name should not be a significant determinant in whether or not someone died in a ship sinking. The same goes for the passenger id, which is just an index variable assigned to the dataset well after the event. \n",
    "\n",
    "In a similar fashion, the ticket number shouldn't really matter either. From pulling the first 7 ticket numbers from the data set, we see that ticket numbers have no clear meaning, as some of the ticket numbers have characters included, and the numbers range from 17463 to 373450, which means that the ticket number does not match the number of passengers either, or boarding order, as the titanic certainly did not have room for 300,000 people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Janitor Work\n",
    "\n",
    "Since we've identified the Name, Ticket and PassengerId columns are not being particularly useful in predicting whether or not a given titanic passenger would've survived, let's drop those first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500   NaN        S\n",
       "1         1       1  female  38.0      1      0  71.2833   C85        C\n",
       "2         1       3  female  26.0      0      0   7.9250   NaN        S\n",
       "3         1       1  female  35.0      1      0  53.1000  C123        S\n",
       "4         0       3    male  35.0      0      0   8.0500   NaN        S\n",
       "5         0       3    male   NaN      0      0   8.4583   NaN        Q\n",
       "6         0       1    male  54.0      0      0  51.8625   E46        S"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop(['PassengerId','Name','Ticket'], axis = 1, inplace = True)\n",
    "train.head(n=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks better. Looks like we might have some missing data (The fifth entry has a missing age value, and the Cabin column has many missing values - 'NaN'). Let's see if we have any missing data values elsewhere in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have some missing data. The Age, Cabin, and Embarked columns have some missing values. We will need to deal with this. \n",
    "\n",
    "A lot of records are missing cabin numbers. Cabin numbers seem to be formatted with a combination of a letter at the beginning, followed by a number. While the letter at the beginning may indicate what section of the ship the passenger was in, \"pclass\" would be an excellent proxy, as what class your ticket was determined what section of the ship you were placed in, and it has no missing values. \n",
    "\n",
    "Let's remove the \"Cabin\" column.\n",
    "\n",
    "The age and the embarked columns are a little more problematic however, and cannot be dealt with by simply removing their columns. \n",
    "\n",
    "We can remove the data entries/ passengers who have missing embarkation data, as there are only two passengers who are missing embarkation data. However, with regards to age, we could drop the age column, but that leaves the issue of us dropping a lot of data - age certainly was a factor in one's survival on the titanic - \"women and children first\". \n",
    "\n",
    "We could just exlude the passenger entries with missing age values, but we don't know how many passengers in the testing data set lack ages. What will happen if our model, if trained with age as an input, needs to guess whether or not a passenger whose age is unknown survived? \n",
    "\n",
    "For now, let's just exclude the passengers with missing age values from our training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "Here are the dimensions of our training dataset in (row, column) form: (712, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500        S\n",
       "1         1       1  female  38.0      1      0  71.2833        C\n",
       "2         1       3  female  26.0      0      0   7.9250        S\n",
       "3         1       1  female  35.0      1      0  53.1000        S\n",
       "4         0       3    male  35.0      0      0   8.0500        S\n",
       "6         0       1    male  54.0      0      0  51.8625        S\n",
       "7         0       3    male   2.0      3      1  21.0750        S"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop(['Cabin'], axis = 1, inplace = True)\n",
    "train.dropna(subset = [\"Age\",\"Embarked\"], inplace = True)\n",
    "print(train.isnull().sum())\n",
    "print(\"Here are the dimensions of our training dataset in (row, column) form: \" + str(train.shape))\n",
    "train.head(n=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. Worth nothing however, is the fact that our training now only has 712 observations, compared to the original 891, a 20% reduction.\n",
    "\n",
    "Now's lets get some summary statistics of the columns to get an idea of how the data is distributed, and to see if there are any persisting issues with data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.404494</td>\n",
       "      <td>2.240169</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0.514045</td>\n",
       "      <td>0.432584</td>\n",
       "      <td>34.567251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.491139</td>\n",
       "      <td>0.836854</td>\n",
       "      <td>14.492933</td>\n",
       "      <td>0.930692</td>\n",
       "      <td>0.854181</td>\n",
       "      <td>52.938648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.645850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count  712.000000  712.000000  712.000000  712.000000  712.000000  712.000000\n",
       "mean     0.404494    2.240169   29.642093    0.514045    0.432584   34.567251\n",
       "std      0.491139    0.836854   14.492933    0.930692    0.854181   52.938648\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    1.000000   20.000000    0.000000    0.000000    8.050000\n",
       "50%      0.000000    2.000000   28.000000    0.000000    0.000000   15.645850\n",
       "75%      1.000000    3.000000   38.000000    1.000000    1.000000   33.000000\n",
       "max      1.000000    3.000000   80.000000    5.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since survived is really just a binary variable, with 1 meaning the passenger survived the sinking and 0 meaning the passenger did not, the mean of the survived variable is actually the proportion of passengers who survived. \n",
    "\n",
    "Pclass's statistics is probably the least interpretable. While the values for Pclass are numeric (1, 2, 3), Pclass should really be a categorical variable. Categorical variable tell us the quality of something, numeric values tell us the quantity. \n",
    "\n",
    "The statistics for the Sex column are not displayed as it is coded as a categorical variable already, only being able to take on the values of \"male\" and \"female\" as opposed to numbers like Pclass. The same goes for the embarked column. \n",
    "\n",
    "Age, SibSp, Parch, and Fare all look normal. \n",
    "SibSp and Parch only take on integer values in the their histograms, which at least shows that there aren't obvious data quality issues.\n",
    "\n",
    "Average age is 29.64. Worth noting is that there are two \"humps\" in the distribution (see age histogram below), with one being near the mean of 29.64, and another smaller one near age 0, which suggests that there was a significant population of infants and children aboard. \n",
    "\n",
    "The average number of siblings/spouses a given passenger had was 0.51\n",
    "The average number of parents/children a given passenger had was 0.43\n",
    "The average fare paid by passengers is 34.56\n",
    "\n",
    "Let's plot histograms of the variables, and see if there are any issues in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5v4/wUaueCQninEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24d0f12b630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24d0f155518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24d0f6f72e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24d0f5576a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24d0f71fa58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwgloXL/nDDUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24d10835828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nylsqrAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24d108695c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for column_name in train.columns.values:\n",
    "    try:\n",
    "        histo = train.hist(column = column_name, bins = 25)\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass \n",
    "# use try/except because pandas will give you an error if you try to plot a histogram of a column with non-number values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms are in line with expectations based off the descriptive statistics, and are in line with intuition and common sense (i.e. no negative numbers for any of the variables, and integer only values for SibSp and Parch) \n",
    "\n",
    "Since logistic regressions can only accept numerical input, we need turn several variables into dummy variables.\n",
    "Instead of having C, Q, and S as the values for the Embarked variable, we'll just have dummy variables. For example: let Embarked C be equal to 1 if the value for the Embarked column was C, and 0 otherwise, and the same for Embarked Q and S. \n",
    "\n",
    "As mentioned before, we need to process the Pclass column and turn it into a categorical variable. The same goes for the Sex and Embarked columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  Pclass_3  \\\n",
       "0         0  22.0      1      0   7.2500         0         0         1   \n",
       "1         1  38.0      1      0  71.2833         1         0         0   \n",
       "2         1  26.0      0      0   7.9250         0         0         1   \n",
       "3         1  35.0      1      0  53.1000         1         0         0   \n",
       "4         0  35.0      0      0   8.0500         0         0         1   \n",
       "6         0  54.0      0      0  51.8625         1         0         0   \n",
       "7         0   2.0      3      1  21.0750         0         0         1   \n",
       "\n",
       "   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0           0         1           0           0           1  \n",
       "1           1         0           1           0           0  \n",
       "2           1         0           0           0           1  \n",
       "3           1         0           0           0           1  \n",
       "4           0         1           0           0           1  \n",
       "6           0         1           0           0           1  \n",
       "7           0         1           0           0           1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.get_dummies(data = train, columns = ['Pclass', 'Sex', 'Embarked'])\n",
    "train.head(n = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks good. We'll need to drop one dummy variable for each of our three original categorical variables. This is so we can establish a \"baseline\" category. For example, if we drop the sex_male column, the model will assume the passenger is male unless otherwise specified by the sex_female column with a 1. We'll pick the most common category for each categorical variable to be our baseline (see histograms above), and in this case, the baseline assumption is 3rd class, Male, and embarked at Southhampton, until otherwise specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  Sex_female  \\\n",
       "0         0  22.0      1      0   7.2500         0         0           0   \n",
       "1         1  38.0      1      0  71.2833         1         0           1   \n",
       "2         1  26.0      0      0   7.9250         0         0           1   \n",
       "3         1  35.0      1      0  53.1000         1         0           1   \n",
       "4         0  35.0      0      0   8.0500         0         0           0   \n",
       "6         0  54.0      0      0  51.8625         1         0           0   \n",
       "7         0   2.0      3      1  21.0750         0         0           0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  \n",
       "0           0           0  \n",
       "1           1           0  \n",
       "2           0           0  \n",
       "3           0           0  \n",
       "4           0           0  \n",
       "6           0           0  \n",
       "7           0           0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()\n",
    "train.drop(['Pclass_3', 'Sex_male', 'Embarked_S'], axis = 1, inplace = True)\n",
    "train.head(n = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting\n",
    "## Generalized Linear Model (Logistic Regression)\n",
    "\n",
    "Let's finally build a model to predict passenger survivorship based off our now cleaned data. We'll be fitting a logistic regression (a kind of Generalized Linear Model or GLM) which will output a number between 0 and 1, with 0 being a prediction of dying, and 1 being a prediction of surviving. We can interpret numbers between 0 and 1 as how likely a passenger with the given attributes would survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.452866\n",
      "         Iterations 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jintoboy\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>Survived</td>     <th>  No. Observations:  </th>  <td>   712</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   703</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     8</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 07 Feb 2018</td> <th>  Pseudo R-squ.:     </th>  <td>0.3289</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>18:39:15</td>     <th>  Log-Likelihood:    </th> <td> -322.44</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -480.45</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.595e-63</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>        <td>   -0.0661</td> <td>    0.006</td> <td>  -11.569</td> <td> 0.000</td> <td>   -0.077</td> <td>   -0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SibSp</th>      <td>   -0.5178</td> <td>    0.124</td> <td>   -4.189</td> <td> 0.000</td> <td>   -0.760</td> <td>   -0.276</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Parch</th>      <td>   -0.1032</td> <td>    0.130</td> <td>   -0.797</td> <td> 0.426</td> <td>   -0.357</td> <td>    0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fare</th>       <td>    0.0008</td> <td>    0.003</td> <td>    0.317</td> <td> 0.751</td> <td>   -0.004</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pclass_1</th>   <td>    2.5375</td> <td>    0.342</td> <td>    7.420</td> <td> 0.000</td> <td>    1.867</td> <td>    3.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pclass_2</th>   <td>    1.0168</td> <td>    0.241</td> <td>    4.225</td> <td> 0.000</td> <td>    0.545</td> <td>    1.488</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sex_female</th> <td>    2.5375</td> <td>    0.225</td> <td>   11.301</td> <td> 0.000</td> <td>    2.097</td> <td>    2.978</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Embarked_C</th> <td>    0.2207</td> <td>    0.273</td> <td>    0.808</td> <td> 0.419</td> <td>   -0.314</td> <td>    0.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Embarked_Q</th> <td>   -0.6983</td> <td>    0.566</td> <td>   -1.234</td> <td> 0.217</td> <td>   -1.807</td> <td>    0.411</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               Survived   No. Observations:                  712\n",
       "Model:                          Logit   Df Residuals:                      703\n",
       "Method:                           MLE   Df Model:                            8\n",
       "Date:                Wed, 07 Feb 2018   Pseudo R-squ.:                  0.3289\n",
       "Time:                        18:39:15   Log-Likelihood:                -322.44\n",
       "converged:                       True   LL-Null:                       -480.45\n",
       "                                        LLR p-value:                 1.595e-63\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Age           -0.0661      0.006    -11.569      0.000      -0.077      -0.055\n",
       "SibSp         -0.5178      0.124     -4.189      0.000      -0.760      -0.276\n",
       "Parch         -0.1032      0.130     -0.797      0.426      -0.357       0.151\n",
       "Fare           0.0008      0.003      0.317      0.751      -0.004       0.006\n",
       "Pclass_1       2.5375      0.342      7.420      0.000       1.867       3.208\n",
       "Pclass_2       1.0168      0.241      4.225      0.000       0.545       1.488\n",
       "Sex_female     2.5375      0.225     11.301      0.000       2.097       2.978\n",
       "Embarked_C     0.2207      0.273      0.808      0.419      -0.314       0.756\n",
       "Embarked_Q    -0.6983      0.566     -1.234      0.217      -1.807       0.411\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "train_cols =  train.columns[1:]\n",
    "logit = sm.Logit(train['Survived'], train[train_cols])\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table is a table of the results from training our logistic model. Some figures to note are the Pseudo R-Squared figure which shows how good our model predicts survival, and the various coefficients of our variables and their respective P-values, which shows the relative \"importance\" of our variables in determining survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.910778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.695323</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.270818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.145319</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  Sex_female  \\\n",
       "0         0  22.0      1      0   7.2500         0         0           0   \n",
       "1         1  38.0      1      0  71.2833         1         0           1   \n",
       "2         1  26.0      0      0   7.9250         0         0           1   \n",
       "3         1  35.0      1      0  53.1000         1         0           1   \n",
       "4         0  35.0      0      0   8.0500         0         0           0   \n",
       "6         0  54.0      0      0  51.8625         1         0           0   \n",
       "7         0   2.0      3      1  21.0750         0         0           0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Probability  Predicted  \n",
       "0           0           0     0.122793          0  \n",
       "1           1           0     0.910778          1  \n",
       "2           0           0     0.695323          1  \n",
       "3           0           0     0.907727          1  \n",
       "4           0           0     0.090530          0  \n",
       "6           0           0     0.270818          0  \n",
       "7           0           0     0.145319          0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display\n",
    "train_age = train.copy() #save the dataframe before we add our predictions to it\n",
    "train['Probability'] = result.predict(train[train_cols])\n",
    "train['Predicted'] = np.where(train['Probability'] >= 0.5, 1 ,0)\n",
    "train.head(n = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the model we've trained using the training set, we can output the model's confidence of a given passenger surviving, as seen in the probability column. To better evaluate model performance, we discretize the confidence output: survival probabilities above 0.5 will be considered to have survived and less than 0.5 will be considered to have died. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Died</th>\n",
       "      <th>Survived</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Died</th>\n",
       "      <td>361</td>\n",
       "      <td>63</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>74</td>\n",
       "      <td>214</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>435</td>\n",
       "      <td>277</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Died  Survived  All\n",
       "Actual                        \n",
       "Died        361        63  424\n",
       "Survived     74       214  288\n",
       "All         435       277  712"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# confusion_matrix(train['Survived'], train['Predicted'])\n",
    "\n",
    "train_cmatrix = pd.crosstab(np.where(train['Survived'] == 1, 'Survived', 'Died'), \n",
    "                            np.where(train['Predicted'] == 1, 'Survived', 'Died'),\n",
    "                            rownames=['Actual'],\n",
    "                            colnames=['Predicted'],\n",
    "                            margins=True)\n",
    "display(train_cmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is a confusion matrix, which shows what happened in reality vs. what the model predicted. For example, out of the 712 passengers in the training dataset, there were 63 instances where the model predicted that they would survive, when in reality they had died. \n",
    "\n",
    "We can use the F1 score to quantify how well our GLM is performing. It is the harmonic average of precision and recall, with precision being the proportion of predicted survivors that had actually survived, and recall being the proportion of all actual survivors being predicted to survive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 Score of the model on the training dataset is 0.757522123894\n"
     ]
    }
   ],
   "source": [
    "train_tp = train_cmatrix['Survived']['Survived']\n",
    "train_fp = train_cmatrix['Survived']['Died']\n",
    "train_fn = train_cmatrix['Died']['Survived']\n",
    "train_precision = train_tp/(train_tp + train_fp)\n",
    "train_recall = train_tp/(train_tp + train_fn)\n",
    "train_f1 = 2/(train_precision**-1 + train_recall**-1)\n",
    "print(\"The F1 Score of the model on the training dataset is \" + str(train_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 scores range from 0 to 1, where 1 is perfect performance (all actual survivors are predicted to survive by the model, with no false positives/ negatives). Our model is, at the very least, acceptable, and is doing better than random guessing. \n",
    "\n",
    "# Initial Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the dimensions of our testing dataset, before removing rows with missing data, in (row, column) form: (418, 14)\n",
      "Here are the dimensions of our testing dataset, after removing rows with missing data, in (row, column) form: (332, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.144568</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615876</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285355</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.465603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  Sex_female  \\\n",
       "0         0  34.5      0      0   7.8292         0         0           0   \n",
       "1         1  47.0      1      0   7.0000         0         0           1   \n",
       "2         0  62.0      0      0   9.6875         0         1           0   \n",
       "3         0  27.0      0      0   8.6625         0         0           0   \n",
       "4         1  22.0      1      1  12.2875         0         0           1   \n",
       "5         0  14.0      0      0   9.2250         0         0           0   \n",
       "6         1  30.0      0      0   7.6292         0         0           1   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Probability  Predicted  \n",
       "0           0           1     0.048680          0  \n",
       "1           0           0     0.253208          0  \n",
       "2           0           1     0.022485          0  \n",
       "3           0           0     0.144568          0  \n",
       "4           0           0     0.615876          1  \n",
       "5           0           0     0.285355          0  \n",
       "6           0           1     0.465603          0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    survival = pd.DataFrame.from_csv('C:/Users/vlee/PycharmProjects/Jupyter-Notebooks/Kaggle/Titanic/Data/gender_submission.csv', index_col = None)\n",
    "    test = pd.DataFrame.from_csv('C:/Users/vlee/PycharmProjects/Jupyter-Notebooks/Kaggle/Titanic/Data/test.csv', index_col = None)\n",
    "except:\n",
    "    survival = pd.DataFrame.from_csv('C:/Users/Jintoboy/PycharmProjects/Jupyter-Notebooks/Kaggle/Titanic/Data/gender_submission.csv', index_col = None)\n",
    "    test = pd.DataFrame.from_csv('C:/Users/Jintoboy/PycharmProjects/Jupyter-Notebooks/Kaggle/Titanic/Data/test.csv', index_col = None)\n",
    "\n",
    "test.drop(['Name','Ticket','Cabin'], axis = 1, inplace = True)\n",
    "test = pd.get_dummies(data = test, columns = ['Pclass', 'Sex', 'Embarked'])\n",
    "test = survival.merge(test, on = 'PassengerId')\n",
    "print(\"Here are the dimensions of our testing dataset, before removing rows with missing data, in (row, column) form: \" + str(test.shape))\n",
    "\n",
    "test_missing = test[pd.isnull(test['Age'])].copy()\n",
    "test_missing.drop(['PassengerId', 'Pclass_3', 'Sex_male', 'Embarked_S'], axis = 1, inplace = True)\n",
    "\n",
    "test.dropna(subset = ['Age'], inplace = True)\n",
    "test.drop(['PassengerId', 'Pclass_3', 'Sex_male', 'Embarked_S'], axis = 1, inplace = True)\n",
    "test_cols = test.columns[1:]\n",
    "test['Probability'] =  result.predict(test[test_cols])\n",
    "test['Predicted'] = np.where(test['Probability'] >= 0.5, 1, 0)\n",
    "print(\"Here are the dimensions of our testing dataset, after removing rows with missing data, in (row, column) form: \" + str(test.shape))\n",
    "test.head(n = 7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that around 20% of our testing data has missing age values, and needed to be removed. This is similar to the proportion of passengers we removed from the training set. We will deal with predictions for passengers with missing data values later. For now, let's see how our model performs on passengers with complete infomration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Died</th>\n",
       "      <th>Survived</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Died</th>\n",
       "      <td>184</td>\n",
       "      <td>21</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>14</td>\n",
       "      <td>113</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>198</td>\n",
       "      <td>134</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Died  Survived  All\n",
       "Actual                        \n",
       "Died        184        21  205\n",
       "Survived     14       113  127\n",
       "All         198       134  332"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 Score of the model on the test dataset is 0.865900383142\n"
     ]
    }
   ],
   "source": [
    "test_cmatrix = pd.crosstab(np.where(test['Survived'] == 1, 'Survived', 'Died'), \n",
    "                            np.where(test['Predicted'] == 1, 'Survived', 'Died'),\n",
    "                            rownames=['Actual'],\n",
    "                            colnames=['Predicted'],\n",
    "                            margins=True)\n",
    "display(test_cmatrix)\n",
    "test_tp = test_cmatrix['Survived']['Survived']\n",
    "test_fp = test_cmatrix['Survived']['Died']\n",
    "test_fn = test_cmatrix['Died']['Survived']\n",
    "test_precision = test_tp/(test_tp + test_fp)\n",
    "test_recall = test_tp/(test_tp + test_fn)\n",
    "test_f1 = 2/(test_precision**-1 + test_recall**-1)\n",
    "print(\"The F1 Score of the model on the test dataset is \" + str(test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Strangely enough, the model seems to have a better time predicting survival on the testing set, a set it's never \"seen\" before, as opposed to the training set on which it was trained on. This is a sign that the model generalizes well, as opposed to being overfit. This might be a sign that the model isn't learning as much as it could be from the training set. \n",
    "\n",
    "# Data Imputation\n",
    "\n",
    "But what about all the passengers whose ages weren't recorded? We could simply just not predict survival chances for them, but that's honestly a cheap cop-out, and we're ignoring around 20% of all passengers.\n",
    "\n",
    "We could train another GLM that doesn't rely on age information, but based on historical(\"Women and children first!\") and statistical(The age variable in our original GLM is highly significant in determining survival chances) reasons, that would not be a good idea. We would weaken the predictive power of our model.\n",
    "\n",
    "Since our GLM only takes passengers whose information records are complete we need to find away to deal with people without ages recorded.\n",
    "\n",
    "## Mean Value Imputation\n",
    "\n",
    "A fast, basic approach to data imputation is to simply take the mean value of the column with missing values, and use the mean to fill in observations with missing variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.6833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.6792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived  Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  Sex_female  \\\n",
       "10         0  NaN      0      0   7.8958         0         0           0   \n",
       "22         1  NaN      0      0  31.6833         1         0           1   \n",
       "29         0  NaN      2      0  21.6792         0         0           0   \n",
       "33         1  NaN      1      2  23.4500         0         0           1   \n",
       "36         1  NaN      0      0   8.0500         0         0           1   \n",
       "39         0  NaN      0      0  56.4958         0         0           0   \n",
       "41         0  NaN      0      0  26.5500         1         0           0   \n",
       "\n",
       "    Embarked_C  Embarked_Q  \n",
       "10           0           0  \n",
       "22           0           0  \n",
       "29           1           0  \n",
       "33           0           0  \n",
       "36           0           0  \n",
       "39           0           0  \n",
       "41           0           0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_missing.head(n = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.6833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.6792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived        Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  \\\n",
       "10         0  29.642093      0      0   7.8958         0         0   \n",
       "22         1  29.642093      0      0  31.6833         1         0   \n",
       "29         0  29.642093      2      0  21.6792         0         0   \n",
       "33         1  29.642093      1      2  23.4500         0         0   \n",
       "36         1  29.642093      0      0   8.0500         0         0   \n",
       "39         0  29.642093      0      0  56.4958         0         0   \n",
       "41         0  29.642093      0      0  26.5500         1         0   \n",
       "\n",
       "    Sex_female  Embarked_C  Embarked_Q  \n",
       "10           0           0           0  \n",
       "22           1           0           0  \n",
       "29           0           1           0  \n",
       "33           1           0           0  \n",
       "36           1           0           0  \n",
       "39           0           0           0  \n",
       "41           0           0           0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_missing_alt = test_missing.copy()\n",
    "test_missing.loc[:, 'Age'] = train['Age'].mean()\n",
    "test_missing.head(n = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.6833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.958551</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.6792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.059698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.468212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.642094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.645512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived        Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  \\\n",
       "10         0  29.642093      0      0   7.8958         0         0   \n",
       "22         1  29.642093      0      0  31.6833         1         0   \n",
       "29         0  29.642093      2      0  21.6792         0         0   \n",
       "33         1  29.642093      1      2  23.4500         0         0   \n",
       "36         1  29.642093      0      0   8.0500         0         0   \n",
       "39         0  29.642093      0      0  56.4958         0         0   \n",
       "41         0  29.642093      0      0  26.5500         1         0   \n",
       "\n",
       "    Sex_female  Embarked_C  Embarked_Q  Probability  Predicted  \n",
       "10           0           0           0     0.124213          0  \n",
       "22           1           0           0     0.958551          1  \n",
       "29           0           1           0     0.059698          0  \n",
       "33           1           0           0     0.468212          0  \n",
       "36           1           0           0     0.642094          1  \n",
       "39           0           0           0     0.128518          0  \n",
       "41           0           0           0     0.645512          1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_missing_cols = test_missing.columns[1:]\n",
    "test_missing['Probability'] =  result.predict(test_missing[test_cols])\n",
    "test_missing['Predicted'] = np.where(test_missing['Probability'] >= 0.5, 1, 0)\n",
    "test_missing.head(n = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Died</th>\n",
       "      <th>Survived</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Died</th>\n",
       "      <td>54</td>\n",
       "      <td>7</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>69</td>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Died  Survived  All\n",
       "Actual                        \n",
       "Died         54         7   61\n",
       "Survived     15        10   25\n",
       "All          69        17   86"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 Score of the model on the test dataset is 0.47619047619\n"
     ]
    }
   ],
   "source": [
    "test_missing_cmatrix = pd.crosstab(np.where(test_missing['Survived'] == 1, 'Survived', 'Died'), \n",
    "                            np.where(test_missing['Predicted'] == 1, 'Survived', 'Died'),\n",
    "                            rownames=['Actual'],\n",
    "                            colnames=['Predicted'],\n",
    "                            margins=True)\n",
    "display(test_missing_cmatrix)\n",
    "test_missing_tp = test_missing_cmatrix['Survived']['Survived']\n",
    "test_missing_fp = test_missing_cmatrix['Survived']['Died']\n",
    "test_missing_fn = test_missing_cmatrix['Died']['Survived']\n",
    "test_missing_precision = test_missing_tp/(test_missing_tp + test_missing_fp)\n",
    "test_missing_recall = test_missing_tp/(test_missing_tp + test_missing_fn)\n",
    "test_missing_f1 = 2/(test_missing_precision**-1 + test_missing_recall**-1)\n",
    "print(\"The F1 Score of the model on the test dataset is \" + str(test_missing_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After replacing the missing passenger ages with the average passenger age from the training set, we get a lower F1 score compared to the F1 score of the testing dataset without missing age values. \n",
    "\n",
    "While now we can finally predict the survival of passengers whose age is unknown, the fact that we imputed age with the average age seems to have had a negative impact in terms of model performance. This is because age is one of the variables with the highest impact on survival (see the z-values from the logistic model regression results), and we lose a lot of predictive power if we just use the average age. \n",
    "\n",
    "## Regression Imputation\n",
    "\n",
    "Since we have age data on roughly 80% of the passengers, we can impute the missing ages using another model.\n",
    "\n",
    "We'll use another logistic regression to predict passenger's ages based on the remaining variables: Sibling/spouse count, Parent/children count, gender, embarkation point, ticket class, and fare. \n",
    "\n",
    "While logistic regressions are typically used to predict binary variables (such as dead/alive in our previous model), it has a useful property that we can exploit: it only returns values between 0 and 1. This lets us restrict the range of age predictions our model makes, so that we won't get non-sensical values such as negative ages or extremely high ages. \n",
    "\n",
    "We can transform the age values such that they're within the [0, 1] range that the logistic model can handle.\n",
    "\n",
    "Data normalization involved scaling a variable so that all possible values are between 0 and 1, where 0 and 1 are the minimum and maximum values of the variable, repsectively.\n",
    "\n",
    "$$x_{normalized} = \\frac {x_{original} - x_{minimum}}{x_{maximum} - x_{minimum}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.625066\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Age</td>       <th>  No. Observations:  </th>  <td>   712</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   704</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 07 Feb 2018</td> <th>  Pseudo R-squ.:     </th> <td>0.005224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>18:39:15</td>     <th>  Log-Likelihood:    </th> <td> -445.05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -447.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>0.6996</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SibSp</th>      <td>   -0.3678</td> <td>    0.107</td> <td>   -3.451</td> <td> 0.001</td> <td>   -0.577</td> <td>   -0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Parch</th>      <td>   -0.0992</td> <td>    0.108</td> <td>   -0.916</td> <td> 0.360</td> <td>   -0.311</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fare</th>       <td>   -0.0013</td> <td>    0.002</td> <td>   -0.647</td> <td> 0.518</td> <td>   -0.005</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pclass_1</th>   <td>    0.4956</td> <td>    0.229</td> <td>    2.161</td> <td> 0.031</td> <td>    0.046</td> <td>    0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pclass_2</th>   <td>   -0.1466</td> <td>    0.174</td> <td>   -0.841</td> <td> 0.400</td> <td>   -0.488</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sex_female</th> <td>   -0.3453</td> <td>    0.168</td> <td>   -2.052</td> <td> 0.040</td> <td>   -0.675</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Embarked_C</th> <td>   -0.3215</td> <td>    0.216</td> <td>   -1.486</td> <td> 0.137</td> <td>   -0.745</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Embarked_Q</th> <td>   -0.2167</td> <td>    0.412</td> <td>   -0.526</td> <td> 0.599</td> <td>   -1.024</td> <td>    0.591</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                    Age   No. Observations:                  712\n",
       "Model:                          Logit   Df Residuals:                      704\n",
       "Method:                           MLE   Df Model:                            7\n",
       "Date:                Wed, 07 Feb 2018   Pseudo R-squ.:                0.005224\n",
       "Time:                        18:39:15   Log-Likelihood:                -445.05\n",
       "converged:                       True   LL-Null:                       -447.38\n",
       "                                        LLR p-value:                    0.6996\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "SibSp         -0.3678      0.107     -3.451      0.001      -0.577      -0.159\n",
       "Parch         -0.0992      0.108     -0.916      0.360      -0.311       0.113\n",
       "Fare          -0.0013      0.002     -0.647      0.518      -0.005       0.003\n",
       "Pclass_1       0.4956      0.229      2.161      0.031       0.046       0.945\n",
       "Pclass_2      -0.1466      0.174     -0.841      0.400      -0.488       0.195\n",
       "Sex_female    -0.3453      0.168     -2.052      0.040      -0.675      -0.016\n",
       "Embarked_C    -0.3215      0.216     -1.486      0.137      -0.745       0.102\n",
       "Embarked_Q    -0.2167      0.412     -0.526      0.599      -1.024       0.591\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "train_age = train.drop(['Survived', 'Probability', 'Predicted'], axis = 1, inplace = False)\n",
    "# age_min = 0\n",
    "# age_max = 80\n",
    "import numpy as np\n",
    "train_cols = train_age.columns[1:]\n",
    "scaler_age = preprocessing.MinMaxScaler(feature_range = (0, 1)).fit(train_age[['Age']])\n",
    "train_age.loc[:, 'Age'] = scaler_age.transform(train_age[['Age']])\n",
    "age_model = sm.Logit(train_age['Age'], train_age[train_cols])\n",
    "age_model_result = age_model.fit()\n",
    "age_model_result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.796061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.067371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.211580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.566513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.004635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.617580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.426420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  Sex_female  Embarked_C  \\\n",
       "0  22.0      1      0   7.2500         0         0           0           0   \n",
       "1  38.0      1      0  71.2833         1         0           1           1   \n",
       "2  26.0      0      0   7.9250         0         0           1           0   \n",
       "3  35.0      1      0  53.1000         1         0           1           0   \n",
       "4  35.0      0      0   8.0500         0         0           0           0   \n",
       "6  54.0      0      0  51.8625         1         0           0           0   \n",
       "7   2.0      3      1  21.0750         0         0           0           0   \n",
       "\n",
       "   Embarked_Q  Predicted  \n",
       "0           0  32.796061  \n",
       "1           0  28.067371  \n",
       "2           0  33.211580  \n",
       "3           0  34.566513  \n",
       "4           0  40.004635  \n",
       "6           0  48.617580  \n",
       "7           0  18.426420  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_age['Predicted'] = scaler_age.inverse_transform(age_model_result.predict(train_age[train_cols]).values.reshape(-1, 1))\n",
    "train_age.loc[:, 'Age'] = scaler_age.inverse_transform(train_age[['Age']])\n",
    "train_age.head(n = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting our logistic regression, we'll need to see how much of a performance boost is it compared to just using the mean age. We'll need to quantify performance using a different method than using a confusion matrix/ F1 score, since those only make sense for models that predict class/category (i.e. survived/ died). Since we're predicting age, a continuous variable, we'll use the sum of squared error measure. For each passenger, we'll take the squared difference between the predicted and actual age (so it'll always be positive), and then sum up the errors for all passengers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Sum of Squared Errors for regression imputation is 142249.12414522178\n",
      "The Sum of Squared Errors for mean-value imputation is 149342.06898188204\n",
      "The regression imputation method has a squared error sum 4.749462013627759% greater than the mean imputation method\n"
     ]
    }
   ],
   "source": [
    "squared_error_regression = ((train_age['Age'] - train_age['Predicted']) ** 2).sum()\n",
    "squared_error_mean = ((train_age['Age'] - train_age['Age'].mean()) ** 2).sum()\n",
    "print(\"The Sum of Squared Errors for regression imputation is \" + str(squared_error_regression))\n",
    "print(\"The Sum of Squared Errors for mean-value imputation is \"+ str(squared_error_mean))\n",
    "performance_percentage = squared_error_regression/squared_error_mean\n",
    "if performance_percentage < 1:\n",
    "    print(\"The regression imputation method has a squared error sum \" + \n",
    "          str(100 * (1 - performance_percentage)) + \n",
    "          \"% greater than the mean imputation method\")\n",
    "else:     print(\"The regression imputation method has a squared error sum \" + \n",
    "          str(100 * (performance_percentage - 1)) + \n",
    "          \"% less than the mean imputation method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our age GLM (logistic regression) does not predict age any better than than just using the mean age when it comes to accuracy.\n",
    "\n",
    "Nevertheless, since our survival GLM relies on age heavily, let's see how our survival GLM performs based on the ages the age GLM predicted for our ageless passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>40.008568</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066708</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>42.389009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.6833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.908739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>20.521309</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.6792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>22.749545</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>33.208490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.586305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>38.769339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>49.232345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.332783</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived        Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  \\\n",
       "10         0  40.008568      0      0   7.8958         0         0   \n",
       "22         1  42.389009      0      0  31.6833         1         0   \n",
       "29         0  20.521309      2      0  21.6792         0         0   \n",
       "33         1  22.749545      1      2  23.4500         0         0   \n",
       "36         1  33.208490      0      0   8.0500         0         0   \n",
       "39         0  38.769339      0      0  56.4958         0         0   \n",
       "41         0  49.232345      0      0  26.5500         1         0   \n",
       "\n",
       "    Sex_female  Embarked_C  Embarked_Q  Probability  Predicted  \n",
       "10           0           0           0     0.066708          0  \n",
       "22           1           0           0     0.908739          1  \n",
       "29           0           1           0     0.103959          0  \n",
       "33           1           0           0     0.581346          1  \n",
       "36           1           0           0     0.586305          1  \n",
       "39           0           0           0     0.074642          0  \n",
       "41           0           0           0     0.332783          0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_missing_alt['Age'] = scaler_age.inverse_transform(age_model_result.predict(test_missing_alt[train_cols]).values.reshape(-1, 1))\n",
    "test_missing_alt['Probability'] = result.predict(test_missing_alt[test_cols])\n",
    "test_missing_alt['Predicted'] = np.where(test_missing_alt['Probability'] >= 0.5, 1, 0)\n",
    "test_missing_alt.head(n = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Died</th>\n",
       "      <th>Survived</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Died</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>74</td>\n",
       "      <td>12</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Died  Survived  All\n",
       "Actual                        \n",
       "Died         61         0   61\n",
       "Survived     13        12   25\n",
       "All          74        12   86"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 Score of the model on the test dataset is 0.648648648649\n",
      "Using regression imputation results in a 36.2162162162% increase in the F1 score\n"
     ]
    }
   ],
   "source": [
    "test_missing_alt_cmatrix = pd.crosstab(np.where(test_missing_alt['Survived'] == 1, 'Survived', 'Died'), \n",
    "                            np.where(test_missing_alt['Predicted'] == 1, 'Survived', 'Died'),\n",
    "                            rownames=['Actual'],\n",
    "                            colnames=['Predicted'],\n",
    "                            margins=True)\n",
    "display(test_missing_alt_cmatrix)\n",
    "test_missing_alt_tp = test_missing_alt_cmatrix['Survived']['Survived']\n",
    "test_missing_alt_fp = test_missing_alt_cmatrix['Survived']['Died']\n",
    "test_missing_alt_fn = test_missing_alt_cmatrix['Died']['Survived']\n",
    "test_missing_alt_precision = test_missing_alt_tp/(test_missing_alt_tp + test_missing_alt_fp)\n",
    "test_missing_alt_recall = test_missing_alt_tp/(test_missing_alt_tp + test_missing_alt_fn)\n",
    "test_missing_alt_f1 = 2/(test_missing_alt_precision**-1 + test_missing_alt_recall**-1)\n",
    "print(\"The F1 Score of the model on the test dataset is \" + str(test_missing_alt_f1))\n",
    "print(\"Using regression imputation results in a \" + str(((test_missing_alt_f1 - test_missing_f1)/(test_missing_f1)) * 100) + \"% increase in the F1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our age GLM to predict passenger ages only in a ~4.7% increase in squared errors as opposed to just using the average age, when we used the GLM-predicted ages to predict survival, we got a 36% improvement in the F1 score among the ageless passengers. Not an intuitive result, but perhaps using the sum of squared errors as a way to evalute model accuracy was not a good way to estimate model performance in this case. Regardless,there are certainly some very promising results. \n",
    "\n",
    "For the sake of practice and completeness, let's try using other algorithms to try to predict passenger survival.\n",
    "\n",
    "# Model Fitting\n",
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector machines attempt to find the plane of maximum seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Died</th>\n",
       "      <th>Survived</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Died</th>\n",
       "      <td>360</td>\n",
       "      <td>64</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>93</td>\n",
       "      <td>195</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>453</td>\n",
       "      <td>259</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Died  Survived  All\n",
       "Actual                        \n",
       "Died        360        64  424\n",
       "Survived     93       195  288\n",
       "All         453       259  712"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 Score of the SVM model on the training dataset is 0.712979890311\n"
     ]
    }
   ],
   "source": [
    "# initialize training and testing datasets for SVM fitting and prediction\n",
    "train_svm = train.drop(['Probability','Predicted'], axis = 1, inplace = False)\n",
    "test_svm = test.drop(['Probability','Predicted'], axis = 1, inplace = False)\n",
    "\n",
    "scaled_train_svm = train_svm.copy()\n",
    "scaler_svm = preprocessing.MinMaxScaler().fit(scaled_train_svm[['Age', 'SibSp', 'Parch', 'Fare']])\n",
    "scaled_train_svm[['Age', 'SibSp', 'Parch', 'Fare']] = scaler_svm.transform(scaled_train_svm[['Age', 'SibSp', 'Parch', 'Fare']])\n",
    "\n",
    "from sklearn import svm\n",
    "train_cols = scaled_train_svm.columns[1:]\n",
    "survivalsvm = svm.SVC(kernel = 'rbf', gamma = 0.001, C = 1000, decision_function_shape = 'ovr').fit(scaled_train_svm[train_cols], scaled_train_svm['Survived'])\n",
    "scaled_train_svm['Predicted'] = survivalsvm.predict(scaled_train_svm[train_cols])\n",
    "\n",
    "train_svm_cmatrix = pd.crosstab(np.where(scaled_train_svm['Survived'] == 1, 'Survived', 'Died'), \n",
    "                            np.where(scaled_train_svm['Predicted'] == 1, 'Survived', 'Died'),\n",
    "                            rownames=['Actual'],\n",
    "                            colnames=['Predicted'],\n",
    "                            margins=True)\n",
    "display(train_svm_cmatrix)\n",
    "\n",
    "train_svm_tp = train_svm_cmatrix['Survived']['Survived']\n",
    "train_svm_fp = train_svm_cmatrix['Survived']['Died']\n",
    "train_svm_fn = train_svm_cmatrix['Died']['Survived']\n",
    "train_svm_precision = train_svm_tp/(train_svm_tp + train_svm_fp)\n",
    "train_svm_recall = train_svm_tp/(train_svm_tp + train_svm_fn)\n",
    "train_svm_f1 = 2/(train_svm_precision**-1 + train_svm_recall**-1)\n",
    "print(\"The F1 Score of the SVM model on the training dataset is \" + str(train_svm_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'SibSp', 'Parch', 'Fare', 'Pclass_1', 'Pclass_2', 'Sex_female',\n",
      "       'Embarked_C', 'Embarked_Q'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Died</th>\n",
       "      <th>Survived</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Died</th>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>204</td>\n",
       "      <td>127</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Died  Survived  All\n",
       "Actual                        \n",
       "Died        204         0  204\n",
       "Survived      0       127  127\n",
       "All         204       127  331"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 Score of the SVM model on the testing dataset is 1.0\n"
     ]
    }
   ],
   "source": [
    "print(train_cols)\n",
    "scaled_test_svm = test_svm.copy()\n",
    "scaled_test_svm.dropna(inplace = True)\n",
    "scaled_test_svm[['Age', 'SibSp', 'Parch', 'Fare']] = scaler_svm.transform(scaled_test_svm[['Age', 'SibSp', 'Parch', 'Fare']])\n",
    "scaled_test_svm['Predicted'] = survivalsvm.predict(scaled_test_svm[train_cols])\n",
    "\n",
    "test_svm_cmatrix = pd.crosstab(np.where(scaled_test_svm['Survived'] == 1, 'Survived', 'Died'), \n",
    "                            np.where(scaled_test_svm['Predicted'] == 1, 'Survived', 'Died'),\n",
    "                            rownames=['Actual'],\n",
    "                            colnames=['Predicted'],\n",
    "                            margins=True)\n",
    "display(test_svm_cmatrix)\n",
    "\n",
    "test_svm_tp = test_svm_cmatrix['Survived']['Survived']\n",
    "test_svm_fp = test_svm_cmatrix['Survived']['Died']\n",
    "test_svm_fn = test_svm_cmatrix['Died']['Survived']\n",
    "test_svm_precision = test_svm_tp/(test_svm_tp + test_svm_fp)\n",
    "test_svm_recall = test_svm_tp/(test_svm_tp + test_svm_fn)\n",
    "test_svm_f1 = 2/(test_svm_precision**-1 + test_svm_recall**-1)\n",
    "print(\"The F1 Score of the SVM model on the testing dataset is \" + str(test_svm_f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
